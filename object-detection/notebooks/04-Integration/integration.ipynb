{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center\">\n",
    "<img src=\"../../assets/images/dtlogo.png\" alt=\"Duckietown\" width=\"50%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection for robots\n",
    "\n",
    "## Integration\n",
    "\n",
    "Finally, we need to integrate our model with ROS. We can do so by editing the file [`integration_activity.py`](../../packages/solution/integration_activity.py).\n",
    "\n",
    "\n",
    "### Simulation ðŸ’»\n",
    "If you don't have a Jetson Nano Duckiebot, you can run this exercise locally with the simulator. This will run your code as a Pytorch model. This means that we rely on your host machine's CPU or GPU to run your model.\n",
    "\n",
    "### Hardware ðŸš™\n",
    "\n",
    "If you have a Jetson Nano Duckiebot, you can run this exercise on your Duckiebot. This will convert your model to a TensorRT model, and run it your Jetson Nano's GPU.\n",
    "\n",
    "### What we are doing in this notebook\n",
    "\n",
    "In both cases, we need to edit the ROS node to decide how we will use the detections.\n",
    "Should you call your model on every image from your camera? Only once every 4-5 frames, to preserve your CPU?\n",
    "You might also want to change your robot's behaviour depending on the size of the detection.\n",
    "If it is small, the object is probably far away, so there's no need to stop.\n",
    "\n",
    "To get started, open the [`integration_activity.py`](../../packages/solution/integration_activity.py) file in the `packages/solution` directory.\n",
    "\n",
    "You'll first need to input your information into the `DT_TOKEN` and `MODEL_NAME` functions. Follow the `TODO` markers in both functions to copy in your Duckietown token and the name of your uploaded model from the previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can use `dts code build` and `dts code workbench` (either with `--sim` for in simulation or with `-b <DUCKIEBOT_NAME>` for the real Duckiebot) to see it in action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "### Framerate\n",
    "\n",
    "While object detection is useful, it is also very expensive, computationally.\n",
    "\n",
    "One trick used to reduce said cost is to only call the full model infrequently.\n",
    "For example, one might call the model only a few times a second, which is very slow in\n",
    "computer timeframes, but relatively fast for the real world. \n",
    "\n",
    "Of course, this varies from application to application. In very dynamic, fast\n",
    "robotic environments, clearly the model should be called more frequently.\n",
    "\n",
    "You can fine-tune this yourself: edit the `NUMBER_FRAMES_SKIPPED` function in the [`integration_activity.py`](../../packages/solution/integration_activity.py) file to indicate the number of frames\n",
    "your robot should skip before calling its object detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In real life, we would use a full neural network model to produce very accurate\n",
    "predictions, and then a less accurate model coupled with a Kalman filter (or\n",
    "other such estimation system) to \"track\" each prediction during the skipped frames.\n",
    "\n",
    "For this exercises, we will limit ourselves to just skipping frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Some of your predictions might not actually be useful. For example, in Duckietown,\n",
    "the trucks and busses are always parked on the side of the road. Your robot will\n",
    "never have to avoid or stop for them.\n",
    "\n",
    "Cones can be in the road in some maps, but for this exercises, you can assume that there\n",
    "aren't any.\n",
    "\n",
    "#### Filtering by class\n",
    "\n",
    "For this reason, you probably want to remove all non-duckies from your predictions,\n",
    "since only duckies will be on the road. Update the `filter_by_classes` function to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by score\n",
    "\n",
    "Depending on the model, you might also want to remove very unconfident detections.\n",
    "\n",
    "Then again, your model might not be confident even for detections that are absolutely\n",
    "correct. You should experiment with the `filter_by_scores` function to find a value that works well for your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtering by bounding box\n",
    "\n",
    "Finally, you should also evaluate what each detection *means* in terms of positionning.\n",
    "\n",
    "If a bounding box is in the leftmost or rightmost thirds of the image, it might be the case that\n",
    "the object in not even on the road, and that your robot would be able to go by it without issue.\n",
    "\n",
    "![image of a bounding box](../../assets/images/thirds.png)\n",
    "\n",
    "Also, if a bounding box's area is small, its object is likely far away. So there is no need to\n",
    "try to avoid the object or stop the robot: the robot still has a bit of driving to do before it reaches\n",
    "the object. So filtering out small detections might be a good idea too.  Update the `filter_by_bboxes` function to play around with this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "### Fine-tuning\n",
    "\n",
    "In all of the functions above, there is not objective right answer. You should play with\n",
    "your functions and fine-tune their behaviours. Robotics is an iterative process!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "As mentioned, you can test the behavior of your agent in the simulator with \n",
    "\n",
    "    $ dts code workbench --sim\n",
    "\n",
    "Note that you will need to open the Image Viewer, and then the keyboard control joystick. Once the joystick is up and running, press \"a\" on it to enable automatic lane following.\n",
    "\n",
    "You can test on real hardware with\n",
    "\n",
    "    $ dts code workbench -b <DUCKIEBOT_NAME>\n",
    "   \n",
    "In the case of the real hardware, you will need to be patient. Because of RAM limitations on the Jetson, we need to turn the camera off, then load your model, and then restart the camera. As soon as your model is loaded your robot might start moving! So make sure it is in a safe space. \n",
    "\n",
    "## Debugging\n",
    "\n",
    "After you run `dts code workbench` (either in simulation or on hardware) you can open the VNC using the link that will be provided in your terminal to see what is happening. If you click on the `RQT Image View` icon and then in the dropdown select `/DUCKIEBOT_NAME/object_detection_node/object_detections_img`. This shows an image with your detections overlaid as shown below:\n",
    "\n",
    "![](../../assets/images/rqt_with_duckie.png)\n",
    "\n",
    "\n",
    "# Submission\n",
    "\n",
    "You can test your agent locally with\n",
    "\n",
    "    $ dts code evaluate\n",
    "    \n",
    "\n",
    "And then finally submit with \n",
    "\n",
    "    $ dts code submit\n",
    "    \n",
    "\n",
    "And then check out how you did [on the leaderboard](https://challenges.duckietown.org/v4/humans/challenges/lx22-objdet/leaderboard). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
